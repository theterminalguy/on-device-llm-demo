import {
  FilesetResolver,
  LlmInference,
} from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-genai@0.10.19-rc.20241118";

// DOM elements for user input and displaying results
const userInput = document.getElementById("input");
const resultDisplay = document.getElementById("output");
const actionButton = document.getElementById("submit");

// Path to your local model file, feel free to replace with a suitable model
// See readme for list of supported models
const modelPath = "./gemma2-2b-it-gpu-int8.bin";

/**
 * Updates the output area with the generated text.
 * Handles intermediate results and completes when done.
 *
 * @param {string} generatedText - Partial text generated by the model.
 * @param {boolean} isComplete - Flag indicating if generation is complete.
 */
function updateOutput(generatedText, isComplete) {
  resultDisplay.textContent += generatedText;

  if (isComplete) {
    if (!resultDisplay.textContent.trim()) {
      resultDisplay.textContent = "No content generated.";
    }
    actionButton.disabled = false;
  }
}

/**
 * Initializes the LLM engine and sets up user interaction.
 */
async function initializeApp() {
  try {
    // Load the necessary resources for the LLM engine
    const resourceResolver = await FilesetResolver.forGenAiTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-genai/wasm"
    );

    let inferenceEngine;

    // Configure button to trigger text generation
    if (actionButton && userInput) {
      actionButton.addEventListener("click", () => {
        resultDisplay.textContent = ""; // Clear previous output
        actionButton.disabled = true;

        if (inferenceEngine && userInput.value.trim()) {
          inferenceEngine.generateResponse(userInput.value, updateOutput);
        }
      });

      actionButton.value = "Loading Model...";
    }

    // Create the LLM engine instance
    inferenceEngine = await LlmInference.createFromOptions(resourceResolver, {
      baseOptions: {
        modelAssetPath: modelPath,
        // More parameters such as temperature, model path, etc can be configured as desired
        // See https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inference#configurations_options
      },
    });

    // Enable the button once the model is ready
    actionButton.disabled = false;
    actionButton.value = "Generate Text";
  } catch (error) {
    console.error("Error initializing the application:", error);
    alert("Failed to load the model. Please try again.");
  }
}

// Start the application
initializeApp();
